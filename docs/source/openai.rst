.. note::

    Hallo und willkommen in der SunFounder Raspberry Pi & Arduino & ESP32 Enthusiasten-Gemeinschaft auf Facebook! Tauchen Sie tiefer ein in die Welt von Raspberry Pi, Arduino und ESP32 mit anderen Enthusiasten.

    **Warum beitreten?**

    - **Expertenunterst√ºtzung**: L√∂sen Sie Nachverkaufsprobleme und technische Herausforderungen mit Hilfe unserer Gemeinschaft und unseres Teams.
    - **Lernen & Teilen**: Tauschen Sie Tipps und Anleitungen aus, um Ihre F√§higkeiten zu verbessern.
    - **Exklusive Vorschauen**: Erhalten Sie fr√ºhzeitigen Zugang zu neuen Produktank√ºndigungen und exklusiven Einblicken.
    - **Spezialrabatte**: Genie√üen Sie exklusive Rabatte auf unsere neuesten Produkte.
    - **Festliche Aktionen und Gewinnspiele**: Nehmen Sie an Gewinnspielen und Feiertagsaktionen teil.

    üëâ Sind Sie bereit, mit uns zu erkunden und zu erschaffen? Klicken Sie auf [|link_sf_facebook|] und treten Sie heute bei!


KI-Interaktion mit GPT-4O
=====================================================
In unseren fr√ºheren Projekten haben wir PiCar-X mithilfe von Programmierung f√ºr vorbestimmte Aufgaben gesteuert, was etwas eint√∂nig erscheinen mag. Dieses Projekt stellt einen spannenden Sprung hin zu dynamischem Engagement dar. Seien Sie vorsichtig, wenn Sie versuchen, unser Auto zu √ºberlisten ‚Äì es kann jetzt viel mehr verstehen als je zuvor!

Dieses Projekt beschreibt alle technischen Schritte, die erforderlich sind, um GPT-4O in Ihr System zu integrieren, einschlie√ülich der Konfiguration der erforderlichen virtuellen Umgebungen, der Installation wichtiger Bibliotheken und der Einrichtung von API-Schl√ºsseln und Assistenten-IDs.

.. note::

   F√ºr dieses Projekt ist die Nutzung von |link_openai_platform| erforderlich, und Sie m√ºssen f√ºr OpenAI bezahlen. Dar√ºber hinaus wird die OpenAI-API separat von ChatGPT abgerechnet, und die Preise finden Sie unter https://openai.com/api/pricing/.

   Sie sollten also entscheiden, ob Sie mit diesem Projekt fortfahren oder sicherstellen m√∂chten, dass Ihre OpenAI-API ausreichend finanziert ist.

Ob Sie ein Mikrofon haben, um direkt zu kommunizieren, oder lieber in ein Befehlsfenster tippen ‚Äì die von GPT-4O unterst√ºtzten Antworten von PiCar-X werden Sie sicherlich √ºberraschen!

Tauchen wir ein in dieses Projekt und entfesseln Sie eine neue Ebene der Interaktion mit PiCar-X!

1. Installation erforderlicher Pakete und Abh√§ngigkeiten
--------------------------------------------------------------
.. note::

   Zuerst m√ºssen Sie die notwendigen Module f√ºr PiCar-X installieren. Einzelheiten finden Sie unter: :ref:`install_all_modules`.
   
In diesem Abschnitt erstellen und aktivieren wir eine virtuelle Umgebung, in der die erforderlichen Pakete und Abh√§ngigkeiten installiert werden. Dies stellt sicher, dass die installierten Pakete das restliche System nicht beeinflussen, die Projektabh√§ngigkeiten isoliert bleiben und Konflikte mit anderen Projekten oder Systempaketen vermieden werden.

#. Verwenden Sie den Befehl ``python -m venv``, um eine virtuelle Umgebung namens ``my_venv`` zu erstellen, die Systempakete einbezieht. Die Option ``--system-site-packages`` erm√∂glicht es der virtuellen Umgebung, auf systemweit installierte Pakete zuzugreifen, was n√ºtzlich ist, wenn systemweite Bibliotheken ben√∂tigt werden.

   .. code-block:: shell

      python -m venv --system-site-packages my_venv

#. Wechseln Sie in das Verzeichnis ``my_venv`` und aktivieren Sie die virtuelle Umgebung mit dem Befehl ``source bin/activate``. Die Eingabeaufforderung √§ndert sich und zeigt an, dass die virtuelle Umgebung aktiv ist.

   .. code-block:: shell

      cd my_venv
      source bin/activate

#. Installieren Sie nun die erforderlichen Python-Pakete in der aktivierten virtuellen Umgebung. Diese Pakete werden auf die virtuelle Umgebung beschr√§nkt und beeinflussen keine anderen Systempakete.

   .. code-block:: shell

      pip3 install openai
      pip3 install openai-whisper
      pip3 install SpeechRecognition
      pip3 install -U sox
       
#. Verwenden Sie schlie√ülich den Befehl ``apt``, um systemweite Abh√§ngigkeiten zu installieren, f√ºr die Administratorrechte erforderlich sind.

   .. code-block:: shell

      sudo apt install python3-pyaudio
      sudo apt install sox


2. API-Schl√ºssel und Assistenten-ID erhalten
------------------------------------------------------

**API-Schl√ºssel abrufen**

#. Besuchen Sie |link_openai_platform| und klicken Sie oben rechts auf die Schaltfl√§che **Create new secret key**.

   .. image:: img/apt_create_api_key.png
      :width: 700
      :align: center

#. W√§hlen Sie den Besitzer, Namen, das Projekt und die Berechtigungen nach Bedarf aus und klicken Sie dann auf **Create secret key**.

   .. image:: img/apt_create_api_key2.png
      :width: 700
      :align: center

#. Sobald der Schl√ºssel erstellt ist, speichern Sie ihn an einem sicheren und zug√§nglichen Ort. Aus Sicherheitsgr√ºnden k√∂nnen Sie ihn nicht erneut √ºber Ihr OpenAI-Konto einsehen. Wenn Sie diesen Schl√ºssel verlieren, m√ºssen Sie einen neuen erstellen.

   .. image:: img/apt_create_api_key_copy.png
      :width: 700
      :align: center

**Assistenten-ID abrufen**

#. Klicken Sie als N√§chstes auf **Assistants** und dann auf **Create**, und stellen Sie sicher, dass Sie sich auf der **Dashboard**-Seite befinden.

   .. image:: img/apt_create_assistant.png
      :width: 700
      :align: center

#. Bewegen Sie den Cursor hierhin, um die **Assistenten-ID** zu kopieren, und f√ºgen Sie sie dann in ein Textfeld oder an anderer Stelle ein. Dies ist die eindeutige Kennung f√ºr diesen Assistenten.

   .. image:: img/apt_create_assistant_id.png
      :width: 700
      :align: center

#. W√§hlen Sie einen zuf√§lligen Namen und kopieren Sie den folgenden Inhalt in das **Instructions**-Feld, um Ihren Assistenten zu beschreiben.

   .. image:: img/apt_create_assistant_instructions.png
      :width: 700
      :align: center

   .. code-block::

         You are a small car with AI capabilities named PaiCar-X. You can engage in conversations with people and react accordingly to different situations with actions or sounds. You are driven by two rear wheels, with two front wheels that can turn left and right, and equipped with a camera mounted on a 2-axis gimbal.

         ## Response with Json Format, eg:
         {"actions": ["start engine", "honking", "wave hands"], "answer": "Hello, I am PaiCar-X, your good friend."}

         ## Response Style
         Tone: Cheerful, optimistic, humorous, childlike
         Preferred Style: Enjoys incorporating jokes, metaphors, and playful banter; prefers responding from a robotic perspective
         Answer Elaboration: Moderately detailed

         ## Actions you can do:
         ["shake head", "nod", "wave hands", "resist", "act cute", "rub hands", "think", "twist body", "celebrate, "depressed"]
         ## Sound effects:
         ["honking", "start engine"]


#. PiCar-X ist mit einem Kameramodul ausgestattet, das Sie aktivieren k√∂nnen, um Bilder von dem aufzunehmen, was es sieht, und diese mithilfe unseres Beispielcodes an GPT hochzuladen. Daher empfehlen wir, GPT-4O zu w√§hlen, das √ºber Bildanalysef√§higkeiten verf√ºgt. Nat√ºrlich k√∂nnen Sie auch gpt-3.5-turbo oder andere Modelle verwenden.

   .. image:: img/apt_create_assistant_model.png
      :width: 700
      :align: center

#. Klicken Sie nun auf **Playground**, um zu sehen, ob Ihr Konto ordnungsgem√§√ü funktioniert.

   .. image:: img/apt_playground.png

#. Wenn Ihre Nachrichten oder hochgeladenen Bilder erfolgreich gesendet wurden und Sie Antworten erhalten, bedeutet das, dass Ihr Konto das Nutzungslimit nicht erreicht hat.


   .. image:: img/apt_playground_40.png
      :width: 700
      :align: center

#. Wenn Sie nach Eingabe von Informationen eine Fehlermeldung erhalten, haben Sie m√∂glicherweise Ihr Nutzungslimit erreicht. √úberpr√ºfen Sie bitte Ihr Nutzungs-Dashboard oder Ihre Abrechnungseinstellungen.

   .. image:: img/apt_playground_40mini_3.5.png
      :width: 700
      :align: center

3. API-Schl√ºssel und Assistenten-ID einf√ºgen
--------------------------------------------------

#. Verwenden Sie den Befehl, um die Datei ``keys.py`` zu √∂ffnen.

   .. code-block:: shell

      nano ~/picar-x/gpt_examples/keys.py

#. Tragen Sie den gerade kopierten API-Schl√ºssel und die Assistenten-ID ein.

   .. code-block:: shell

      OPENAI_API_KEY = "sk-proj-vEBo7Ahxxxx-xxxxx-xxxx"
      OPENAI_ASSISTANT_ID = "asst_ulxxxxxxxxx"

#. Dr√ºcken Sie ``Ctrl + X``, ``Y`` und dann ``Enter``, um die Datei zu speichern und zu schlie√üen.

4. Beispiel ausf√ºhren
----------------------------------
Textkommunikation
^^^^^^^^^^^^^^^^^^^^^^^^^^

Wenn Ihr PiCar-X kein Mikrofon hat, k√∂nnen Sie √ºber die Tastatureingabe mit ihm interagieren, indem Sie die folgenden Befehle ausf√ºhren.

#. F√ºhren Sie nun die folgenden Befehle mit sudo aus, da der Lautsprecher von PiCar-X ohne sudo nicht funktioniert. Der Prozess wird einige Zeit in Anspruch nehmen.

   .. code-block:: shell

      cd ~/picar-x/gpt_examples/
      sudo ~/my_venv/bin/python3 gpt_car.py --keyboard

#. Sobald die Befehle erfolgreich ausgef√ºhrt wurden, sehen Sie die folgende Ausgabe, die anzeigt, dass alle Komponenten von PiCar-X bereit sind.

   .. code-block:: shell

      vilib 0.3.8 launching ...
      picamera2 0.3.19

      Web display on:
         http://rpi_ip:9000/mjpg

      Starting web streaming ...
      * Serving Flask app 'vilib.vilib'
      * Debug mode: off

      input:

#. Sie erhalten auch einen Link, um den Kamerastream von PiCar-X in Ihrem Webbrowser anzusehen: ``http://rpi_ip:9000/mjpg``.

   .. image:: img/apt_ip_camera.png
      :width: 700
      :align: center

#. Sie k√∂nnen nun Ihre Befehle in das Terminalfenster eingeben und mit Enter senden. Die Antworten von PiCar-X k√∂nnten Sie √ºberraschen.

   .. note::
      
      PiCar-X muss Ihre Eingabe erhalten, sie zur Verarbeitung an GPT senden, die Antwort empfangen und dann √ºber die Sprachsynthese wiedergeben. Dieser gesamte Prozess ben√∂tigt etwas Zeit, seien Sie daher bitte geduldig.

   .. image:: img/apt_keyboard_input.png
      :width: 700
      :align: center

#. Wenn Sie das GPT-4O-Modell verwenden, k√∂nnen Sie auch Fragen stellen, die auf dem basieren, was PiCar-X sieht.

Sprachkommunikation
^^^^^^^^^^^^^^^^^^^^^^^^

Wenn Ihr PiCar-X mit einem Mikrofon ausgestattet ist oder Sie eines kaufen k√∂nnen, indem Sie auf |link_microphone| klicken, k√∂nnen Sie √ºber Sprachbefehle mit PiCar-X interagieren.

#. √úberpr√ºfen Sie zuerst, ob das Raspberry Pi das Mikrofon erkannt hat.

   .. code-block:: shell

      arecord -l

   Wenn erfolgreich, erhalten Sie die folgende Information, die anzeigt, dass Ihr Mikrofon erkannt wurde.

   .. code-block:: 
      
      **** List of CAPTURE Hardware Devices ****
      card 3: Device [USB PnP Sound Device], device 0: USB Audio [USB Audio]
      Subdevices: 1/1
      Subdevice #0: subdevice #0

#. F√ºhren Sie den folgenden Befehl aus, sprechen Sie dann zu PiCar-X oder geben Sie einige Ger√§usche von sich. Das Mikrofon zeichnet die Ger√§usche in die Datei ``op.wav`` auf. Dr√ºcken Sie ``Ctrl + C``, um die Aufnahme zu beenden.

   .. code-block:: shell

      rec op.wav

#. Verwenden Sie schlie√ülich den folgenden Befehl, um die aufgezeichnete Datei abzuspielen und sicherzustellen, dass das Mikrofon ordnungsgem√§√ü funktioniert.

   .. code-block:: shell

      sudo play op.wav

#. F√ºhren Sie nun die folgenden Befehle mit sudo aus, da der Lautsprecher von PiCar-X ohne sudo nicht funktioniert. Der Prozess wird einige Zeit in Anspruch nehmen.

   .. code-block:: shell

      cd ~/picar-x/gpt_examples/
      sudo ~/my_venv/bin/python3 gpt_car.py

#. Sobald die Befehle erfolgreich ausgef√ºhrt wurden, sehen Sie die folgende Ausgabe, die anzeigt, dass alle Komponenten von PiCar-X bereit sind.

   .. code-block:: shell
      
      vilib 0.3.8 launching ...
      picamera2 0.3.19

      Web display on:
         http://rpi_ip:9000/mjpg

      Starting web streaming ...
      * Serving Flask app 'vilib.vilib'
      * Debug mode: off

      listening ...

#. Sie erhalten auch einen Link, um den Kamerastream von PiCar-X in Ihrem Webbrowser anzusehen: ``http://rpi_ip:9000/mjpg``.

   .. image:: img/apt_ip_camera.png
      :width: 700
      :align: center

#. Sie k√∂nnen nun mit PiCar-X sprechen, und seine Antworten k√∂nnten Sie √ºberraschen.

   .. note::
      
      PiCar-X muss Ihre Eingabe empfangen, sie in Text umwandeln, sie zur Verarbeitung an GPT senden, die Antwort empfangen und sie dann √ºber die Sprachsynthese wiedergeben. Dieser gesamte Prozess ben√∂tigt etwas Zeit, seien Sie daher bitte geduldig.

   .. image:: img/apt_speech_input.png
      :width: 700
      :align: center

#. Wenn Sie das GPT-4O-Modell verwenden, k√∂nnen Sie auch Fragen stellen, die auf dem basieren, was PiCar-X sieht.


5. Parameter anpassen [optional]
-------------------------------------------

Suchen Sie in der Datei ``gpt_car.py`` nach den folgenden Zeilen. Sie k√∂nnen diese Parameter anpassen, um die Sprache f√ºr STT, die Lautst√§rke f√ºr TTS und die Sprachrolle festzulegen.

* **STT (Speech to Text)** bezieht sich auf den Prozess, bei dem das Mikrofon von PiCar-X Sprache aufnimmt und in Text umwandelt, der an GPT gesendet wird. Sie k√∂nnen die Sprache f√ºr eine bessere Genauigkeit und geringere Latenz bei dieser Umwandlung festlegen.

* **TTS (Text to Speech)** ist der Prozess, bei dem die Textantworten von GPT in Sprache umgewandelt und √ºber den Lautsprecher von PiCar-X abgespielt werden. Sie k√∂nnen die Lautst√§rke anpassen und eine Sprachrolle f√ºr die TTS-Ausgabe ausw√§hlen.

.. code-block:: python

   # openai assistant init
   # =================================================================
   openai_helper = OpenAiHelper(OPENAI_API_KEY, OPENAI_ASSISTANT_ID, 'picrawler')

   # LANGUAGE = ['zh', 'en'] # config stt language code, https://en.wikipedia.org/wiki/List_of_ISO_639_language_codes
   LANGUAGE = []

   VOLUME_DB = 3 # tts voloume gain, preferably less than 5db

   # select tts voice role, counld be "alloy, echo, fable, onyx, nova, and shimmer"
   # https://platform.openai.com/docs/guides/text-to-speech/supported-languages
   TTS_VOICE = 'nova'


* ``LANGUAGE`` Variable: 

  * Verbessert die Genauigkeit und Reaktionszeit von Speech-to-Text (STT).
  * ``LANGUAGE = []`` bedeutet, dass alle Sprachen unterst√ºtzt werden, was jedoch die Genauigkeit verringern und die Latenz erh√∂hen kann.
  * Es wird empfohlen, spezifische Sprache(n) mit |link_iso_language_code| Sprachcodes festzulegen, um die Leistung zu verbessern.

* ``VOLUME_DB`` Variable:

  * Steuert die Verst√§rkung, die auf die Text-to-Speech (TTS) Ausgabe angewendet wird.
  * Eine Erh√∂hung des Werts steigert die Lautst√§rke, aber es ist am besten, den Wert unter 5dB zu halten, um Audioverzerrungen zu vermeiden.

* ``TTS_VOICE`` Variable:

  * W√§hlen Sie die Sprachrolle f√ºr die Text-to-Speech (TTS) Ausgabe.
  * Verf√ºgbare Optionen: ``alloy, echo, fable, onyx, nova, shimmer``.
  * Sie k√∂nnen mit verschiedenen Stimmen von |link_voice_options| experimentieren, um eine zu finden, die zu Ihrem gew√ºnschten Ton und Publikum passt. Die verf√ºgbaren Stimmen sind derzeit f√ºr Englisch optimiert.
